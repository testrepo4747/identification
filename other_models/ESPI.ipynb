{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "selected-career",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())\n",
    "print(\"Num GPUs:\", torch.cuda.device_count())\n",
    "print(\"GPU Name:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"No GPU\")\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "torch.cuda.set_device(device)\n",
    "# torch.cuda.empty_cache()\n",
    "print(f'Using device: {device}, {torch.cuda.get_device_name(device)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blank-chaos",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import numpy\n",
    "print(numpy.__version__)\n",
    "\n",
    "import cupy\n",
    "\n",
    "# Load the model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Enable GPU\n",
    "spacy.require_gpu()\n",
    "\n",
    "# Test to ensure it's using GPU\n",
    "doc = nlp(\"This is a test document.\")\n",
    "print(doc[0].vector)  # Accessing the vector of the first token to make sure all works fine.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "manufactured-dance",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to clean and normalize text\n",
    "def clean_text(text):\n",
    "    return text.encode('ascii', 'ignore').decode('ascii')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def process_dataframe(df):\n",
    "    # Modify this based on the actual preprocessing steps needed from the notebook\n",
    "#     df['manually_label'] = df['manually_label'].map({'positive': 1, 'negative': 0})\n",
    "    \n",
    "    dic_list = []\n",
    "    for index,row in df.iterrows():\n",
    "        res = row['manually_label'] \n",
    "\n",
    "        if res == \"positive\":\n",
    "            row['manually_label'] = 1\n",
    "        elif res == \"negative\":\n",
    "            row['manually_label'] = 0\n",
    "\n",
    "        if res == '1.0':\n",
    "            row['manually_label'] = 1\n",
    "        elif res == '0.0':\n",
    "            row['manually_label'] = 0\n",
    "\n",
    "        if res == '1':\n",
    "            row['manually_label'] = 1\n",
    "        elif res == '0':\n",
    "            row['manually_label'] = 0\n",
    "\n",
    "        dic_list.append(row)\n",
    "    \n",
    "\n",
    "    \n",
    "    df_split = pd.DataFrame(dic_list)\n",
    "#     df_split = a\n",
    "\n",
    "    df_pos = df_split.loc[df_split['manually_label'] == 1]\n",
    "    df_neg = df_split.loc[df_split['manually_label'] == 0]\n",
    "    df_pos1 = df_split.loc[df_split['manually_label'] == '1']\n",
    "    df_neg1 = df_split.loc[df_split['manually_label'] == '0']\n",
    "\n",
    "    print(\"pos:{}, neg:{}\".format(df_pos.shape,df_neg.shape))\n",
    "    print(\"pos:{}, neg:{}\".format(df_pos1.shape,df_neg1.shape))\n",
    "    \n",
    "    df= pd.concat([df_pos,df_pos1, df_neg,df_neg1], ignore_index = True)\n",
    "    df['clean_message'] = df['clean_message'].astype(str)\n",
    "\n",
    "    df['clean_message'] = df['clean_message'].apply(clean_text)\n",
    "    \n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "herbal-greenhouse",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "import networkx as nx\n",
    "from spacy.tokens import Token\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Load the SpaCy model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def build_dependency_graph(commit_message):\n",
    "    doc = nlp(commit_message)\n",
    "    graph = nx.DiGraph()\n",
    "    last_token_of_previous_sentence = None\n",
    "\n",
    "    for sentence in doc.sents:\n",
    "        first_token_of_sentence = True\n",
    "        for token in sentence:\n",
    "            graph.add_node(token.i, label=token.text, feature=token.vector)\n",
    "            if token.head != token:\n",
    "                graph.add_edge(token.head.i, token.i, label=token.dep_)\n",
    "\n",
    "            if first_token_of_sentence and last_token_of_previous_sentence is not None:\n",
    "                graph.add_edge(last_token_of_previous_sentence.i, token.i, label='neigh')\n",
    "                first_token_of_sentence = False\n",
    "\n",
    "            last_token_of_previous_sentence = token\n",
    "\n",
    "    return graph\n",
    "\n",
    "# Load the CSV file\n",
    "df = pd.read_csv('./train.csv')\n",
    "df =  process_dataframe(df)\n",
    "\n",
    "# Apply function with progress bar\n",
    "tqdm.pandas(desc=\"Building graphs\")\n",
    "df['graph'] = df['clean_message'].progress_apply(build_dependency_graph)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compound-verse",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.nn import GatedGraphConv, global_max_pool\n",
    "from torch_geometric.loader import DataLoader  # Instead of from torch_geometric.data import DataLoader\n",
    "from torch_geometric.data import Data\n",
    "import numpy as np\n",
    "\n",
    "class GGNNModel(torch.nn.Module):\n",
    "    def __init__(self, node_feature_dim, num_classes):\n",
    "        super(GGNNModel, self).__init__()\n",
    "        self.ggnn = GatedGraphConv(node_feature_dim, num_layers=3)\n",
    "        self.fc = torch.nn.Linear(node_feature_dim, num_classes)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = self.ggnn(x, edge_index)\n",
    "        x = global_max_pool(x, data.batch)  # Max pooling over all nodes\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "# Assuming node features are already initialized in the graph data\n",
    "# Prepare for training\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = GGNNModel(node_feature_dim=128, num_classes=2).to(device)  # Example dimensions\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "strange-wisconsin",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "import numpy as np\n",
    "import cupy  # Make sure to import cupy\n",
    "\n",
    "def convert_to_torch_geometric(graph, label):\n",
    "    if graph is None or len(graph.nodes()) == 0 or len(graph.edges()) == 0:\n",
    "        print(\"Empty graph or missing data.\")\n",
    "        return None\n",
    "\n",
    "    node_features = []\n",
    "    edge_indices = []\n",
    "\n",
    "    try:\n",
    "        # Collect node features and edges\n",
    "        for node in graph.nodes(data=True):\n",
    "            feature = node[1].get('feature')\n",
    "            if feature is None:\n",
    "                print(f\"Missing feature for node {node}\")\n",
    "                return None\n",
    "            if isinstance(feature, cupy._core.core.ndarray):\n",
    "                feature = cupy.asnumpy(feature)  # Convert CuPy array to NumPy array\n",
    "            if isinstance(feature, np.ndarray):\n",
    "                feature = feature.tolist()  # Convert NumPy array to list\n",
    "            elif not isinstance(feature, list):\n",
    "                print(f\"Invalid feature type for node {node}: {type(feature)}\")\n",
    "                return None\n",
    "            node_features.append(feature)\n",
    "\n",
    "        for edge in graph.edges():\n",
    "            edge_indices.append([edge[0], edge[1]])\n",
    "\n",
    "        if not node_features or not edge_indices:\n",
    "            print(\"No features or edges found for graph conversion.\")\n",
    "            return None\n",
    "\n",
    "        # Convert to tensors\n",
    "        x = torch.tensor(node_features, dtype=torch.float32)\n",
    "        edge_index = torch.tensor(edge_indices, dtype=torch.long).t().contiguous()\n",
    "\n",
    "        # Create PyTorch Geometric data object\n",
    "        data = Data(x=x, edge_index=edge_index)\n",
    "        data.y = torch.tensor([label], dtype=torch.long)\n",
    "        return data\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error converting graph: {e}\")\n",
    "        return None\n",
    "\n",
    "# Testing the conversion function with sample data\n",
    "if not df.empty:\n",
    "    sample_graph = build_dependency_graph(df['clean_message'].iloc[0])\n",
    "    sample_label = df['manually_label'].iloc[0]\n",
    "    sample_data = convert_to_torch_geometric(sample_graph, sample_label)\n",
    "    print(f\"Converted sample data: {sample_data}\")\n",
    "else:\n",
    "    print(\"DataFrame is empty, check data loading.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ordinary-sharing",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = [convert_to_torch_geometric(g, label) for g, label in zip(df['graph'], df['manually_label']) if g is not None]\n",
    "data_list = [d for d in data_list if d is not None]  # Filter out None values\n",
    "print(f\"Total graphs converted and not None: {len(data_list)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "desperate-savings",
   "metadata": {},
   "outputs": [],
   "source": [
    "if data_list:\n",
    "    loader = DataLoader(data_list, batch_size=32, shuffle=True)\n",
    "    print(f\"Data ready for training with {len(data_list)} items.\")\n",
    "else:\n",
    "    print(\"No valid graph data available for DataLoader.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incredible-limitation",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Check if there is any data to process\n",
    "if data_list:\n",
    "    try:\n",
    "        # Set up a progress bar using tqdm for better visualization of the training process\n",
    "        from tqdm import tqdm\n",
    "        \n",
    "        # Begin the training loop\n",
    "        for epoch in range(10):  # Number of epochs\n",
    "            epoch_loss = 0\n",
    "            total = 0\n",
    "            for data in tqdm(loader, desc=f\"Epoch {epoch+1}/{10}\", leave=True):\n",
    "                data = data.to(device)  # Move data to the appropriate device (GPU or CPU)\n",
    "                optimizer.zero_grad()  # Clear gradients to prevent them from accumulating\n",
    "                out = model(data)  # Pass the data through the model\n",
    "                loss = criterion(out, data.y)  # Compute the loss\n",
    "                loss.backward()  # Compute the gradient of the loss wrt the parameters (backpropagation)\n",
    "                optimizer.step()  # Update the parameters based on the gradients\n",
    "                epoch_loss += loss.item() * data.num_graphs  # Aggregate the loss for this epoch\n",
    "                total += data.num_graphs\n",
    "\n",
    "            # Calculate average loss for the epoch\n",
    "            epoch_loss /= total\n",
    "            print(f'Average Loss for Epoch {epoch+1}: {epoch_loss:.4f}')\n",
    "    except Exception as e:\n",
    "        print(f\"Training error occurred: {e}\")  # Print any exceptions that occur during training\n",
    "else:\n",
    "    print(\"Training aborted due to no data.\")  # Message if there is no data to train on\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "korean-tobago",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "torch.save(model.state_dict(), './espi_ggnn_model_(js)_(12_07_24).pth')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "appointed-disposition",
   "metadata": {},
   "source": [
    "## Load and test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brown-citizen",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "model = GGNNModel(node_feature_dim=128, num_classes=2).to(device)\n",
    "model.load_state_dict(torch.load('./espi_ggnn_model(12_07_24).pth'))\n",
    "model.eval()  # Set the model to evaluation mode\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ranging-packet",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch_geometric.loader import DataLoader\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Function to load and preprocess the test dataset\n",
    "def load_and_prepare_test_data(file_path):\n",
    "    # Load the new CSV file\n",
    "    test_df = pd.read_csv(file_path,encoding='utf-8')\n",
    "#     test_data = pd.read_csv('./',encoding='utf-8')\n",
    "    test_df =  process_dataframe(test_df)\n",
    "    \n",
    "    # Apply function with progress bar for building graphs\n",
    "    tqdm.pandas(desc=\"Building test graphs\")\n",
    "    test_df['graph'] = test_df['clean_message'].progress_apply(build_dependency_graph)\n",
    "\n",
    "    # Convert networkx graphs to PyTorch Geometric graphs\n",
    "    test_data_list = [convert_to_torch_geometric(g, label) for g, label in zip(test_df['graph'], test_df['manually_label'])]\n",
    "    test_data_list = [d for d in test_data_list if d is not None]  # Filter out None values to avoid issues in DataLoader\n",
    "\n",
    "    # Check if data is properly loaded and converted\n",
    "    if not test_data_list:\n",
    "        print(\"No valid graph data available for DataLoader in test set.\")\n",
    "        return None\n",
    "    \n",
    "    # Create a DataLoader for the test data\n",
    "    test_loader = DataLoader(test_data_list, batch_size=32, shuffle=False)\n",
    "    print(f\"Data ready for testing with {len(test_data_list)} items.\")\n",
    "    return test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "level-cutting",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch_geometric.loader import DataLoader\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.metrics import accuracy_score, precision_score,classification_report, recall_score, f1_score, confusion_matrix,precision_recall_curve\n",
    "\n",
    "def evaluate_model_on_test_data(model, test_loader):\n",
    "    if test_loader is None:\n",
    "        print(\"Testing aborted due to no data.\")\n",
    "        return\n",
    "    \n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    \n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "    all_probabilities = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data in tqdm(test_loader, desc=\"Testing\"):\n",
    "            data = data.to(device)\n",
    "            outputs = model(data)\n",
    "            _, predicted = torch.max(outputs, dim=1)\n",
    "            probabilities = torch.softmax(outputs, dim=1)[:, 1]  # Get the probabilities for the positive class\n",
    "            all_probabilities.extend(probabilities.cpu().numpy())\n",
    "            all_predictions.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(data.y.cpu().numpy())\n",
    "\n",
    "\n",
    "    conf_matrix = confusion_matrix(all_labels, all_predictions)\n",
    "    # Classification report\n",
    "    report = classification_report(all_labels, all_predictions)\n",
    "    print(\"Classification Report:\\n\", report)\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    comfmat = pd.DataFrame(confusion_matrix(all_labels, all_predictions), index=['negative', 'positive'],columns=['negative', 'positive'])\n",
    "    return comfmat\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "general-purple",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage remains as it was in the previous script, which ends with:\n",
    "# test_loader = load_and_prepare_test_data('./test.csv')\n",
    "\n",
    "test_loader = load_and_prepare_test_data('/20_js_test.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rotary-julian",
   "metadata": {},
   "outputs": [],
   "source": [
    "comfmat = evaluate_model_on_test_data(model, test_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "transparent-batch",
   "metadata": {},
   "outputs": [],
   "source": [
    "comfmat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loose-baking",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3.8_llm",
   "language": "python",
   "name": "py3.8_llm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
